{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce307c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8288480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input text\n",
    "corpus = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, \n",
    "computer science, information engineering, and artificial \n",
    "intelligence concerned with the interactions between computers and human \n",
    "(natural) languages, in particular how to program computers to process and analyze \n",
    "large amounts of natural language data. Challenges in natural language processing \n",
    "frequently involve speech recognition, natural language understanding, and natural \n",
    "language generation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a17ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper function\n",
    "def mapper(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords and non-alphabetic words\n",
    "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stopwords.words('english')]\n",
    "    # Tag each word with its part of speech\n",
    "    tagged_words = pos_tag(words)\n",
    "    # Output (word, tag) pairs\n",
    "    return [(word, tag) for word, tag in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "990017d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(mapped_values):\n",
    "    # Count the occurrences of each (word, tag) pair\n",
    "    tag_counts = Counter(mapped_values)\n",
    "    # Output the word with its most common tag\n",
    "    return [(word, tag) for word, tag in tag_counts.items() if tag_counts[word] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc21878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MapReduce function\n",
    "def map_reduce(corpus):\n",
    "    # Split the corpus into sentences\n",
    "    sentences = nltk.sent_tokenize(corpus)\n",
    "    # Map phase: Apply the mapper function to each sentence\n",
    "    mapped_values = [mapper(sentence) for sentence in sentences]\n",
    "    # Flatten the list of mapped values\n",
    "    mapped_values = [item for sublist in mapped_values for item in sublist]\n",
    "    # Reduce phase: Apply the reducer function to the mapped values\n",
    "    reduced_values = reducer(mapped_values)\n",
    "    return reduced_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f588f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('natural', 'JJ'), 6), (('language', 'NN'), 5), (('processing', 'NN'), 2), (('nlp', 'JJ'), 1), (('subfield', 'NN'), 1), (('linguistics', 'NNS'), 1), (('computer', 'NN'), 1), (('science', 'NN'), 1), (('information', 'NN'), 1), (('engineering', 'NN'), 1), (('artificial', 'JJ'), 1), (('intelligence', 'NN'), 1), (('concerned', 'VBN'), 1), (('interactions', 'NNS'), 1), (('computers', 'NNS'), 2), (('human', 'JJ'), 1), (('languages', 'NNS'), 1), (('particular', 'JJ'), 1), (('program', 'NN'), 1), (('process', 'VBP'), 1), (('analyze', 'JJ'), 1), (('large', 'JJ'), 1), (('amounts', 'NNS'), 1), (('data', 'NNS'), 1), (('challenges', 'NNS'), 1), (('frequently', 'RB'), 1), (('involve', 'VBP'), 1), (('speech', 'NN'), 1), (('recognition', 'NN'), 1), (('understanding', 'JJ'), 1), (('generation', 'NN'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Run the MapReduce program\n",
    "result = map_reduce(corpus)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac9478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
