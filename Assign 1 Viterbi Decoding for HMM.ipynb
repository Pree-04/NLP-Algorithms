{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e723e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc3d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(obs, states, start_prob, trans_prob, emit_prob):\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "\n",
    "    # Initialize base cases (t == 0)\n",
    "    for state in states:\n",
    "        V[0][state] = start_prob[state] * emit_prob[state][obs[0]]\n",
    "        path[state] = [state]\n",
    "\n",
    "    # Run Viterbi algorithm for t > 0\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        new_path = {}\n",
    "\n",
    "        for current_state in states:\n",
    "            (prob, state) = max(\n",
    "                (V[t - 1][prev_state] * trans_prob[prev_state][current_state] * emit_prob[current_state][obs[t]], prev_state)\n",
    "                for prev_state in states\n",
    "            )\n",
    "            V[t][current_state] = prob\n",
    "            new_path[current_state] = path[state] + [current_state]\n",
    "\n",
    "        path = new_path\n",
    "\n",
    "    # Find the highest probability at the last step\n",
    "    (prob, state) = max((V[len(obs) - 1][final_state], final_state) for final_state in states)\n",
    "\n",
    "    return (prob, path[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c45056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['walk', 'shop', 'clean']\n",
    "start_probability = {'Sunny': 0.6, 'Rainy': 0.4}\n",
    "transition_probability = {\n",
    "    'Sunny': {'Sunny': 0.7, 'Rainy': 0.3},\n",
    "    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n",
    "}\n",
    "emission_probability = {\n",
    "    'Sunny': {'walk': 0.1, 'shop': 0.4, 'clean': 0.5},\n",
    "    'Rainy': {'walk': 0.6, 'shop': 0.3, 'clean': 0.1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f621f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely weather sequence: ['Rainy', 'Sunny', 'Sunny']\n"
     ]
    }
   ],
   "source": [
    "prob, path = viterbi_decode(observations, states, start_probability, transition_probability, emission_probability)\n",
    "print(\"Most likely weather sequence:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8ae3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state distribution: [nan nan]\n",
      "Transition matrix: [[nan nan]\n",
      " [nan nan]]\n",
      "Emission probabilities: [[nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "# Example training data\n",
    "X = [[0], [1], [0], [1], [0], [1]]\n",
    "\n",
    "# Initialize HMM model\n",
    "model = hmm.MultinomialHMM(n_components=2, n_iter=100)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X)\n",
    "\n",
    "# Retrieve the trained parameters\n",
    "print(\"Initial state distribution:\", model.startprob_)\n",
    "print(\"Transition matrix:\", model.transmat_)\n",
    "print(\"Emission probabilities:\", model.emissionprob_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfda07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Example training data\n",
    "X_train = [{'feature1': 1, 'feature2': 2}, {'feature1': 2, 'feature2': 3}]\n",
    "y_train = [0, 1]  # Class labels\n",
    "\n",
    "# Convert features to vectors\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Train the maximum entropy model\n",
    "max_ent_model = LogisticRegression()\n",
    "max_ent_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Example usage for prediction\n",
    "X_test = [{'feature1': 3, 'feature2': 4}]  # Test data\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "predicted_labels = max_ent_model.predict(X_test_vectorized)\n",
    "\n",
    "print(\"Predicted labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a8208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
